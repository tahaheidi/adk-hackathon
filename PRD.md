# ðŸ’¡ Product Requirements Document: Heidi AI Multi-Agent Code Quality and Compliance System (CodeName: Project Lighthouse)

---

## I. Strategic Overview and Business Case

### I.A. Executive Summary and Product Vision
**Project Lighthouse** is a mission-critical internal product designed for the highly regulated health-tech environment of Heidi AI. This system utilizes the **Google Agent Development Kit (ADK)** to create a multi-agent orchestration architecture capable of automating comprehensive code review, enforcing stringent **HIPAA** and **GDPR** compliance standards, and embedding specialized, proprietary medical/product knowledge directly into the development pipeline.

The product vision remains to achieve "**Compliance by Commit**," ensuring all code changes meet regulatory and quality benchmarks before merging. This internal quality control is projected to translate directly into a superior, highly reliable customer experience, which serves as a necessary catalyst for increasing the rate of Free-to-Pro customer conversion.

### I.B. Problem Definition: The Three Pillars of Risk
Project Lighthouse is designed to mitigate systemic risks across three interconnected dimensions:

1.  **Regulatory Liability (Highest Risk):** Handling health data means that even minor coding errors can lead to major compliance failures. Current manual review processes are inadequate for consistently preventing critical technical violations, such as the accidental inclusion of PHI in system logs or failure to use mandated encryption standards. These vulnerabilities expose the company to significant financial penalties and irreversible reputational damage.
2.  **Engineering Inefficiency (Velocity Loss):** Repetitive manual security checks, style guide enforcement, and preliminary bug hunting consume valuable developer time, slowing down the **Code Review Velocity (CRV)**. By offloading these tasks to AI agents, Project Lighthouse aims to free engineering talent to focus on complex feature development.
3.  **Revenue Generation Bottleneck (CX/Churn):** High **Defect Density**â€”the number of bugs per unit size of softwareâ€”degrades user trust and frustrates the customer experience (CX). When free users encounter excessive errors, the perceived value of upgrading diminishes significantly.

### I.C. Alignment of Code Quality to SaaS Conversion (The Free-to-Pro Catalyst)
The project's strategic justification rests on a clear causal chain linking internal engineering metrics to external monetization outcomes. Achieving a low Defect Density (with an aspirational benchmark of less than one defect per KLOC) is the primary technical objective. High reliability, resulting from a cleaner codebase, dramatically reduces friction points and customer support incidents, thereby elevating the overall Customer Experience (CX). Enhanced CX and established trust are proven drivers that encourage a free user to recognize sufficient value and confidently upgrade to the paid Pro version.

### I.D. Competitive Analysis and Strategic Advantage
The market for AI code review includes established products offering general bug detection and style suggestions. However, few competitors offer tools specializing in certified, deeply integrated HIPAA or health-specific regulatory intelligence.

The strategic advantage of Project Lighthouse lies in its **specialized knowledge grounding**, enabled by the Google ADK ecosystem.
* The system is architected to include a **Compliance Research Agent** equipped with a **Retrieval Augmented Generation (RAG) tool** powered by **Vertex AI Search Grounding**.
* This mechanism allows the agent to securely access and reference Heidi AI's proprietary, non-public medical coding standards, internal product documentation, and specific interpretations of regulatory guidelines.
* By generating code suggestions grounded in this specialized knowledge, the system can identify and correct nuanced compliance risks unique to the health-tech niche.

---

## II. Core Functional Requirements and Developer Workflow

### II.A. Workflow Integration and Interaction Model
Project Lighthouse is required to operate autonomously yet collaboratively, adopting a "pair programming mindset".

1.  **User Trigger and Execution (NEW):** The system must be executed when a developer provides a **file path or directory** directly to the primary LLMAgent via a command-line interface (CLI) or an integrated development environment (IDE) extension. This replaces the automatic GitHub PR trigger.
2.  **Contextual Output and Planning:** The output generated by the agents must be actionable, clear, and contextualized. For complex tasks or larger required refactors, the agent must adhere to best practices by first generating a step-by-step execution plan (e.g., in a `plan.md` file) and explicitly requesting developer approval before executing major, multi-file code modifications.
3.  **Automated Fix Generation:** For identified issues, the **Refactoring Agent** must utilize its capabilities to generate suggested code blocks or submit a fully autonomous pull request using the granted write permissions. This automated process enhances developer velocity.

### II.B. Required Tooling and Data Access Controls (ADK Tools)
The effectiveness of the multi-agent system hinges on the quality and security of the tools provided to the LlmAgents. Given the stringent security requirements, all tools must be custom-developed or securely provisioned through Google Cloud services.

The **Code Execution Tool** required by the Refactoring Agent must be strictly isolated. This function must be deployed within a secure, sandboxed environment, leveraging the **GKE Code Executor**.

| Required Tool | ADK Type | Integration Mechanism | Primary Security Consideration |
| :--- | :--- | :--- | :--- |
| **Code Snapshot Tool** | Custom Wrapper (File System API/CLI) | Custom function/API call | Enforce **Role-Based Access Control (RBAC)** and adhere to the principle of **least privilege**, retrieving only files/directories specified by the user input. |
| **PHI Tokenizer Tool** | Custom Function (Deterministic) | Isolated module/vault access | Must operate in a highly secure, isolated environment responsible for maintaining the encryption key and the token lookup table securely. |
| **Code Execution Environment** | Pre-built GKE Code Executor | Google Cloud tool | **Sandboxed execution** of AI-generated code to prevent unauthorized system access or data exfiltration. |
| **Heidi AI RAG Engine** | Vertex AI Search Grounding | Google Cloud tool | Securely provides non-public, compliant standards and medical/regulatory documents to the LLM context. |

---

## III. Architectural Specification: The ADK Multi-Agent Pipeline

### III.A. ADK Foundation and LLM Selection Strategy
The Project Lighthouse architecture is built upon the **Google Agent Development Kit (ADK)**, which provides a flexible and modular framework for building and orchestrating specialized agents.

A critical design consideration is managing the **operational expenditure (OPEX)** associated with large language models (LLMs). Complex tasks requiring deep reasoning necessitate premium models like **Gemini 2.5 Pro**, which carry higher costs, versus significantly lower costs for models like **Gemini Flash**.

* To mitigate this, the architecture implements a **tiered LLM strategy** managed by the primary **Routing Agent**.
* This agent, utilizing the Pro model for sophisticated initial risk assessment, dynamically determines if the input code is "**high-risk**" (i.e., touching infrastructure, authentication, or PHI handling code).
* If the risk is low, the workflow is routed through the more cost-effective **Gemini Flash** models (e.g., for basic style and complexity checks).

### III.B. Multi-Agent Orchestration Workflow: Enforcing Sequential Compliance
To guarantee regulatory compliance, the agent workflow must incorporate deterministic control logic. Project Lighthouse employs the **Sequential Agent** as a mandatory wrapper around the most critical processing steps. This ensures that the essential compliance choke pointâ€”**PHI tokenization**â€”occurs before the code is exposed to any non-deterministic LLM for reasoning or analysis.

| Agent Name | ADK Agent Type | LLM Model | Primary Workflow Role | Compliance Function |
| :--- | :--- | :--- | :--- | :--- |
| **1. Routing Agent** | LlmAgent (Dynamic) | Gemini 2.5 Pro | Intake, context analysis, and high-level risk scope determination. | Ensures secure policy enforcement based on code context. |
| **2. Compliance Workflow** | Sequential Agent | N/A (Orchestration) | Executes the PHI Guard, Parallel Analysis, and Research steps in strict, defined order. | **Mandatory Precondition:** Guarantees PHI masking precedes LLM analysis. |
| **3. PHI Guard Agent** | Tool/Deterministic | N/A | Receives raw code snapshot; **tokenizes** all identified PHI patterns (e.g., SSNs, medical record numbers, names). | **Data Firewall:** Prevents PHI exposure to the non-deterministic LLM context (**Privacy by Design**). |
| **4. Parallel Analysis Hub** | Parallel Agent | Gemini Flash | Executes concurrent, high-volume static analysis tasks, focusing on general style, security vulnerabilities, and code complexity. | Efficiently identifies standard best practice issues concurrently. |
| **5. Compliance Researcher** | LlmAgent (Grounding) | Gemini 2.5 Pro | Queries **Heidi AI RAG Engine** (private data store) for specific medical and regulatory standards related to the analyzed code. | Generates contextual, compliant, and medically-relevant security suggestions. |
| **6. Refactoring Agent** | LlmAgent (Reasoning) | Gemini 2.5 Pro | Synthesizes findings from all preceding agents; generates code changes, and validates using the sandboxed **Code Execution Tool**. | Produces high-quality, compliant code fixes and suggested pull requests. |

---

## IV. Compliance-First Design and PHI Handling

### IV.A. Data Protection by Design and Default
Project Lighthouse is fundamentally built on the principles of **Data Protection by Design**. The system must ensure all electronic protected health information (ePHI) is protected through technical safeguards.

* **Encryption and Transit Security:** Data encryption is required for all PHI, both at rest and in transit, using industry-standard algorithms such as **AES-256** and secure protocols like **TLS/HTTPS**.
* **Access Controls:** The Code Snapshot Tool must enforce **Role-Based Access Control (RBAC)** and user authentication, limiting access to raw, un-tokenized code to only those agents and personnel who absolutely require it, adhering to the principle of **least privilege**.
* **Secure Coding Standards:** The Static Code Analysis Agent must enforce secure coding practices mandated for healthcare software, including rigorous input validation to prevent common exploits like **SQL injection** and **Cross-Site Scripting (XSS)**.

### IV.B. Mandatory PHI Tokenization and Secure Logging
The non-deterministic nature of LlmAgents and the potential for unintended data exposure necessitate a strict firewall against raw PHI entering the LLM context.

* **Tokenization:** The solution implemented by the **PHI Guard Agent** is mandatory **tokenization**, rather than simple encryption. Tokenization involves replacing every piece of PHI with a randomly created, unusable ID (the token), while the actual PHI is concealed in a separate, secure vault.
* **Secure Logging:** PHI must never be stored in plaintext in system or agent audit logs. The system must employ techniques such as **data masking**, pseudonymization, or hashing to replace sensitive patient details before storage.

### IV.C. LLM Governance and Auditability Framework
The deployment of an AI system in a regulated environment requires a formal governance framework built on core principles of responsibility and control.

| Pillar | Technical Requirement (ADK Implementation) | Compliance Rationale |
| :--- | :--- | :--- |
| **Accountability** | Assign explicit ownership for the design, training, and prompt engineering of each LlmAgent (Routing, Research, Refactoring). | Ensures clear ownership for the quality and ethical output generated by the AI system. |
| **Auditability** | Implement end-to-end logging of all agent interactions, storing records of the input prompt, tokenized context, tool calls, and final response in a secure, immutable log database (e.g., **BigQuery**). | Essential for maintaining the digital paper trail and audit logs required by **HIPAA** for tracking all access and activity. |
| **Risk Management** | Continuous monitoring of agent behavior to detect anomalies, such as attempts to access unauthorized files, use unexpected tools, or bypass the PHI Guard Agent. | Provides real-time detection and response to mitigate potential unintended consequences, especially regarding data access controls. |
| **Transparency** | LlmAgent outputs must include a verifiable **rationale (chain-of-thought)** for complex suggestions and cite the specific compliance rule or source document (from RAG Engine) justifying the proposed fix. | Promotes developer trust and ensures fixes are based on verifiable regulatory standards, allowing for external audits and review. |

---

## V. Monetization Strategy and Feature Tiering

The monetization strategy must align the specialized, risk-mitigating features required for regulatory safety with the paid **Pro Tier**. The cost of a major compliance breach in a health-tech environment far outweighs the cost of professional tooling.

Features like the **PHI Guard Agent** (tokenization) and the **Compliance Research Agent** (private RAG access) are non-negotiable requirements for safely deploying and managing code that handles PHI. Access to these crucial, risk-mitigating tools becomes the primary gateway feature, justifying the upgrade from the Free to the Pro subscription.

| Feature Category | Free Tier (Engagement Driver) | Pro Tier (Conversion Value) |
| :--- | :--- | :--- |
| **Compliance & PHI** | PHI detection warnings (non-actionable); minimal audit trails; manual mitigation required. | **Full Regulatory Suite:** PHI Guard Agent tokenization; mandated HIPAA/GDPR fix suggestions; end-to-end auditable logs for compliance. |
| **Code Analysis** | General best practices; basic static code analysis; style reviews; uses cost-effective **Gemini Flash** models. | **Deep, Contextual Analysis:** Architectural issues, performance bottlenecks, and highly nuanced security checks utilizing the superior reasoning of **Gemini 2.5 Pro**. |
| **Specialized Knowledge** | General code analysis with public web search grounding only. | **Dedicated Research Agent:** Private Grounding on Heidi AI internal medical/product specific standards via the secure **Vertex AI Search RAG Engine**. |
| **Scalability & Velocity** | Limited usage (e.g., 50 KLOC/month); manual approval for all fixes; limited support queue. | **Full Automation:** Automated fix generation, testing, and PR submission; unlimited usage with dedicated **Vertex AI scaling**; priority support. |

---

## VI. Deployment, Resource Management, and Success Metrics

### VI.A. Deployment Environment and Scalability
Deployment of Project Lighthouse agents will be executed on the **Vertex AI Platform**, which provides the necessary suite of MLOps tools for managing the lifecycle of AI models.

* **Containerization and Consistency:** All ADK agents will be **containerized**.
* **Scalability and Velocity:** Agents will be deployed using **Vertex AI Prediction services**, allowing for auto-scaling of compute resources to handle variable load. Scaling out on optimized AI infrastructure, potentially utilizing specialized hardware such as **NVIDIA T4 GPUs**, ensures that high **Code Review Velocity (CRV)** is maintained even under heavy engineering load.

### VI.B. Operational Cost Strategy
Managing the cost of utilizing advanced LLMs (Gemini 2.5 Pro) requires a two-pronged strategy focused on minimizing token usage and optimizing model interaction frequency.

1.  **Strategic Context Caching:** To prevent repeated, costly re-analysis of stable or large sections of the codebase, **context caching** mechanisms must be implemented. This reduces the input token count by only requiring the LLM to process diffs and related context, rather than the entire codebase for every review.
2.  **Prompt Optimization and "Shift Left" Documentation:** Teams must adhere to prompt engineering best practices. Furthermore, developers are encouraged to "**Shift Left**" in their AI assistance workflow by documenting the codebase early and creating execution plans (like `plan.md`). This preparation reduces the complexity and context size required for the LlmAgent to reason, significantly lowering the per-review input token costs.

### VI.C. Success Metrics (KPIs) and ROI Validation
The success of Project Lighthouse is validated by tracking Key Performance Indicators (KPIs) across four domains, establishing a demonstrable return on investment (ROI).

| KPI Category | Key Performance Indicator (KPI) | Metric Definition | Target Benchmark | Source |
| :--- | :--- | :--- | :--- | :--- |
| **Code Quality (Internal)** | Defect Density | Number of post-release defects per 1,000 Lines of Code (KLOC). | $<1.0$ Defects per KLOC. | 10 |
| **Development Velocity** | Code Review Velocity (CRV) | Average time from code submission (file path/directory input) to successful fix merge. | Decrease review time by $30\%$. | 8 |
| **Security/Compliance** | Critical Vulnerability Fix Rate | Percentage of P1/P2 issues identified by Project Lighthouse that are merged/fixed within one sprint. | $95\%$ fix rate. | 33 |
| **Customer Experience (CX)** | Mean Time to Detect (MTTD) Compliance Issues | Average time taken by the system to detect and flag a compliance violation post-submission. | $<15$ minutes. | 8 |
| **Business Impact (External)** | Free-to-Pro Conversion Rate | Percentage of free users/teams converting to a paid Heidi AI plan. | Increase conversion by $5$ percentage points. | 2 |
| **LLM Efficiency** | Token Cost per Functional Review | Total token cost divided by the number of successful, merged PR reviews. | Target $\$0.50$ or less per functional review. | 26 |

---

## VII. Conclusion and Recommendations
Project Lighthouse represents a critical investment in Heidi AI's stability, regulatory posture, and long-term revenue growth. The analysis confirms that a direct relationship exists between internal code quality (low Defect Density) and external business success (higher Free-to-Pro conversion). By leveraging the Google ADK and strategic LLM tiering, the system can achieve high-fidelity code analysis while managing operational costs effectively.

The most crucial architectural recommendation is the mandatory implementation of the **Sequential Agent workflow** incorporating the **PHI Guard Agent** and its tokenization tool. In the health-tech domain, this approach of enforcing PHI masking prior to non-deterministic LLM processing is not merely a best practice; it is a fundamental security requirement that fulfills the principle of **Privacy by Design**, mitigating the highest pillar of risk (regulatory liability).

It is further recommended that the **governance framework** be established concurrently with development, ensuring that accountability, auditability (via BigQuery logging), and transparency (cited reasoning) are core features, rather than retrofitted additions.